---
title: |
  | \LARGE R Coding
output:
  pdf_document:
    latex_engine: xelatex
mainfont: NanumBarunGothic
fontsize: 11pt
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

# 2
## (1)
```{r}
limp = c(9.0,9.4,4.7,4.8,8.9,4.9,8.4,5.9,6.3,5.7,
         5.0,3.5,7.8,10.4,8.0,8.0,8.6,7.0,6.8,7.1,
         5.7,7.6,6.2,7.1,7.4,8.7,4.9,7.4,6.4,7.1,
         6.3,8.8,8.8,5.2,7.1,5.3,4.7,8.4,6.4,8.3)
tumor = c(12.6,14.6,16.2,23.9,23.3,17.1,20.0,21.0,19.1,19.4,
          16.7,15.9,15.8,16.0,17.9,13.4,19.1,16.6,18.9,18.7,
          20.0,17.8,13.9,22.1,13.9,18.3,22.8,13.0,17.9,15.2,
          17.7,15.1,16.9,16.4,22.8,19.4,19.6,18.4,18.2,20.7)
```

모평균의 차이를 추론하기 위해 정규성을 가정해야한다. Shapro-Wilk Test를 시행한 결과 두 데이터 모두 정규분포를 따른다.
```{r}
shapiro.test(limp)
shapiro.test(tumor)
```

등분산성을 검정하기 위해 F-test를 시행한 결과 두 데이터는 다른 모분산을 갖고 있다. 
```{r}
var.test(limp, tumor)
```

Two sample t-test를 시행한 결과 두 모집단의 평균은 같지 않다. 따라서 림프구세포의 크기가 종양세포의 크기보다 작다고 볼 수 있다.
```{r}
t.test(limp, tumor, alternative = "two.sided", var.equal = FALSE)
```

## (2)
모집단의 정규성, 독립성, 등분산성 가정이 필요하다.

# 5
## (1)
H0: $\mu_1 = \mu_2 = \mu_3$
H1: $\mu_i$들이 모두 같지 않다.

## (2)
One-way ANOVA를 하기 전에 정규성과 등분산성 검정을 실시했다. 그 결과 정규성을 가정할 수 있지만 등분산성은 가정할 수 없다.  
```{r}
y1 = c(22.2,97.8,29.1,37.0,35.8,44.2,82.0,56.0,9.3,19.9,39.5,12.8)
y2 = c(15.1,23.2,10.5,13.9,9.7,19.0,19.8,9.1,30.1,15.5,10.3,11.0)
y3 = c(10.2,11.3,11.4,5.3,14.5,11.0,13.6,33.4,25.0,27.0,36.3,17.7)
y = c(y1, y2, y3)
n = rep(12, 3)
group = rep(1:3, n)
df1 = data.frame(y, group)
df1 = transform(df1, group = factor(group))

#normality test
tapply(y, group, shapiro.test)
#homogenity of variance test
bartlett.test(y ~ group, data = df1)
```

## (2)
등분산성을 만족시키지 않기 때문에 Welch's ANOVA를사용한다.
```{r}
oneway.test(y~group, data=df1, var.equal = F)
```


## (3)
Welch ANOVA를 시행한 결과 p-value가 유의미하게 작기 때문에 집단에 따라 평균이 다른 것을 알 수 있다.

# 7
## (1)
```{r}
d1=c(7.0, 9.9, 8.5, 5.1, 10.3)
d2=c(5.3, 5.7, 4.7, 3.5, 7.7)
d3=c(4.9, 7.6, 5.5, 2.8, 8.4)
d4=c(8.8, 8.9, 8.1, 3.3, 9.1)
tab=matrix(c(d1, d2, d3, d4), ncol=4, byrow=FALSE)
rownames(tab)=c("A", "B", "C", "D", "E")
colnames(tab)=c("d1", "d2", "d3", "d4")
tab=as.table(tab)
df2=as.data.frame(tab)

#homogenity of variance test
library("car")
leveneTest(Freq~Var1, data=df2)
leveneTest(Freq~Var2, data=df2)

#normality of residuals test
resid=residuals(aov(Freq~Var1+Var2, data=df2))
shapiro.test(resid)

summary(aov(Freq~Var1+Var2, data=df2))
```

Var1은 운동방법을 Var2는 식이요법을 일컫는다. Var2의 p-value가 0.05보다 작기 때문에 식이요법에 따라 체중 감량에 차이가 있다고 말할 수 있다.

## (2)
Var1의 p-value를 보면 운동방법의 수준에 따른 체중 감량의 차이가 있다고 말할 수 있다.

## (3)
```{r}
library(DescTools)
ScheffeTest(aov(Freq~Var1+Var2, data=df2))
```

Scheffe 방법을 이용해서 다중 비교를 한 결과 운동방법 D-A, D-B, D-C, E-D 끼리 유의미한 차이가 있고 식이요법은 d2-d1, d3-d1, d4-d3끼리 유의미한 차이가 존재한다.

# 9
## (1)
```{r}
x1=c(25, 28, 22, 18, 23, 19, 17, 24, 19)
x2=c(28, 32, 30, 16, 24, 20, 18, 22, 20)
x3=c(25, 35, 30, 14, 16, 15, 10, 8, 12)
x=c(x1, x2, x3)
var1=c(rep(0, 3), rep(1, 3), rep(2, 3))
var2=c(rep("a1", 9), rep("a2", 9), rep("a3", 9))
df3=data.frame(x, var1, var2)
df3 = transform(df3, var1 = factor(var1))

#homogenity of variance test
library(car)
leveneTest(x~var1*var2, data=df3)

#normality of residuals test
resid=residuals(aov(x~var1*var2, data=df3))
shapiro.test(resid)

aov(x~var1*var2, data=df3)
```

변수간의 등분산성을 만족하며 오차항은 정규분포를 따른다. 따라서 이원 분산분석을 시행할 수 있다. 

## (2)
```{r}
summary(aov(x~var1*var2, data=df3))
```

## (3)

H0: $\alpha_1 = \alpha_2 = \alpha_3=0$ vs H1: $\alpha_i$들이 모두 0이 아니다.

H0: $\beta_1 = \beta_2 = \beta_3=0$ vs H1: $\beta_i$들이 모두 0이 아니다.

H0: $(\alpha\beta)_{ij}=0$ vs H1: $(\alpha\beta)_{ij}$들이 모두 0이 아니다.

분산분석표를 분석해 보면 나이와 마리화나 사용여부간의 유의한 교호작용효과가 있다.

# 1
## (1)
```{r}
library(epitools)
tab1=matrix(c(5, 21, 8, 82), nrow=2, byrow = T)
riskratio(tab1, rev="both")
oddsratio(tab1, rev="both")
```
상대위험률은 2.163, 오즈비는 2.440이다.

## (2)
```{r}
riskratio(tab1, rev="both")$measure
oddsratio(tab1, rev="both")$measure
```

## (3)
상대위험률과 오즈비의 점 처정치를 보면 위험요인을 갖고 있는 집단이 산후 우을증에 걸릴 확률이 더 높다. 하지만 신뢰구간이 1을 포함하고 있으므로 1과 유의한 차이가 있다고 말할 수 없다. 

# 3
## (1)
```{r}
tab2=matrix(c(49, 12, 24, 9, 2, 29), nrow=3, byrow = T)
chisq.test(tab2)
```

P-value가 0.05보다 작으므로 세 그룹간의 재발률이 다르다. 

# 6
```{r}
tab3=matrix(c(1, 5, 8, 2), ncol=2, byrow = T)
fisher.test(tab3)
```

P-value가 0.05보다 작으므로 두 집단에서 안경을 쓴 비율이 다르다고 결론 내릴 수 있다.

# 7
```{r}
tab4=matrix(c(794, 150, 86, 570), nrow=2, byrow = T)
mcnemar.test(tab4, correct = F)
```

P-value가 0.05보다 작으므로 첫번째 투표와 두번째 투표에 유의한 차이가 있다는 것을 알 수 있다. 

# 8
```{r}
tab5=array(c(2, 0, 21, 10,
             2, 0, 40, 18,
             6, 0, 33, 10,
             17, 0, 16, 4),
           dim=c(2, 2, 4),
           dimnames=list(gender=c("male", "female"),
                         survival=c("dead", "alive"),
                         severity=c("0", "1", "2", "3")))
mantelhaen.test(tab5, correct = F)
```

P-value가 유의수준 5%하에서 유의하므로 질병 심각도를 층변수로 제어했을 떄 기증자 성별과 생존 상태 사이에는 유의한 연관성이 있다.

# 9
## (1)
```{r}
library(caret)
tab6=matrix(c(302, 179, 80, 372), nrow = 2)
tab6=as.table(tab6)
dimnames(tab6)=list(pred=c("pos", "neg"), 
                    truth=c("pos", "neg"))
sensitivity(tab6)
specificity(tab6)
```

## (2)
```{r}
posPredValue(tab6, prevalence = 0.1)
negPredValue(tab6, prevalence = 0.1)
```

